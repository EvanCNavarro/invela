5:57:11 AM [info] GET /api/tasks 304 in 89ms :: [{"id":197,"title":"New User Invitation: e.v.a.nc.na.va.r.r.o@gmail.com","des...
[Files] Processing file upload request
[Files] File details: {
  originalname: 'soc2-type2 (1).pdf',
  mimetype: 'application/pdf',
  size: 760657,
  filename: '20250317055709.pdf'
}
[Files] Processing PDF file, extracting first pages
[PDF Service] Starting text extraction from first pages: {
  filePath: '/home/runner/workspace/uploads/documents/20250317055709.pdf',
  maxPages: 3,
  timestamp: '2025-03-17T05:57:12.719Z'
}
[PDF Service] Reading PDF file
[PDF Service] Extraction successful: {
  totalPages: 56,
  extractedPages: 3,
  timestamp: '2025-03-17T05:57:13.549Z'
}
[Files] Starting document classification
[OpenAI Service] Document classification error: BadRequestError: 400 This model's maximum context length is 16385 tokens. However, your messages resulted in 30501 tokens. Please reduce the length of the messages.
    at Function.generate (/home/runner/workspace/node_modules/openai/src/error.ts:72:14)
    at OpenAI.makeStatusError (/home/runner/workspace/node_modules/openai/src/core.ts:443:21)
    at OpenAI.makeRequest (/home/runner/workspace/node_modules/openai/src/core.ts:507:24)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
    at async classifyDocument (/home/runner/workspace/server/services/openai.ts:56:22)
    at async <anonymous> (/home/runner/workspace/server/routes/files.ts:67:28) {
  status: 400,
  headers: {
    'access-control-expose-headers': 'X-Request-ID',
    'alt-svc': 'h3=":443"; ma=86400',
    'cf-cache-status': 'DYNAMIC',
    'cf-ray': '921a406809bd22f9-ORD',
    connection: 'keep-alive',
    'content-length': '282',
    'content-type': 'application/json',
    date: 'Mon, 17 Mar 2025 05:57:13 GMT',
    'openai-organization': '400faces',
    'openai-processing-ms': '94',
    'openai-version': '2020-10-01',
    server: 'cloudflare',
    'set-cookie': '__cf_bm=olCjQm27432_N75AN94qyvHqHip3L8PyWiRiY8F_ZLM-1742191033-1.0.1.1-R1xSVVSi0_LvOsl3I3sEWfU7yTunpaZzQSwOaGUBwbSAqP6r7J_sW7TOVbtu1uV_cyEUy5SdRcee5ep16QbnHhEk3FtS1E3ugWQMUftmyJw; path=/; expires=Mon, 17-Mar-25 06:27:13 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None, _cfuvid=HdUOzAnobdLXcVhhjovhbtiFq5CzfaWOKb.tSl.PopQ-1742191033797-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None',
    'strict-transport-security': 'max-age=31536000; includeSubDomains; preload',
    'x-content-type-options': 'nosniff',
    'x-ratelimit-limit-requests': '10000',
    'x-ratelimit-limit-tokens': '200000',
    'x-ratelimit-remaining-requests': '9999',
    'x-ratelimit-remaining-tokens': '163460',
    'x-ratelimit-reset-requests': '8.64s',
    'x-ratelimit-reset-tokens': '10.962s',
    'x-request-id': 'req_1350ca15ff92d05955cd79b201aae3b5'
  },
  request_id: 'req_1350ca15ff92d05955cd79b201aae3b5',
  error: {
    message: "This model's maximum context length is 16385 tokens. However, your messages resulted in 30501 tokens. Please reduce the length of the messages.",
    type: 'invalid_request_error',
    param: 'messages',
    code: 'context_length_exceeded'
  },
  code: 'context_length_exceeded',
  param: 'messages',
  type: 'invalid_request_error'
}
[Files] Error processing upload: BadRequestError: 400 This model's maximum context length is 16385 tokens. However, your messages resulted in 30501 tokens. Please reduce the length of the messages.
    at Function.generate (/home/runner/workspace/node_modules/openai/src/error.ts:72:14)
    at OpenAI.makeStatusError (/home/runner/workspace/node_modules/openai/src/core.ts:443:21)
    at OpenAI.makeRequest (/home/runner/workspace/node_modules/openai/src/core.ts:507:24)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
    at async classifyDocument (/home/runner/workspace/server/services/openai.ts:56:22)
    at async <anonymous> (/home/runner/workspace/server/routes/files.ts:67:28) {
  status: 400,
  headers: {
    'access-control-expose-headers': 'X-Request-ID',
    'alt-svc': 'h3=":443"; ma=86400',
    'cf-cache-status': 'DYNAMIC',
    'cf-ray': '921a406809bd22f9-ORD',
    connection: 'keep-alive',
    'content-length': '282',
    'content-type': 'application/json',
    date: 'Mon, 17 Mar 2025 05:57:13 GMT',
    'openai-organization': '400faces',
    'openai-processing-ms': '94',
    'openai-version': '2020-10-01',
    server: 'cloudflare',
    'set-cookie': '__cf_bm=olCjQm27432_N75AN94qyvHqHip3L8PyWiRiY8F_ZLM-1742191033-1.0.1.1-R1xSVVSi0_LvOsl3I3sEWfU7yTunpaZzQSwOaGUBwbSAqP6r7J_sW7TOVbtu1uV_cyEUy5SdRcee5ep16QbnHhEk3FtS1E3ugWQMUftmyJw; path=/; expires=Mon, 17-Mar-25 06:27:13 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None, _cfuvid=HdUOzAnobdLXcVhhjovhbtiFq5CzfaWOKb.tSl.PopQ-1742191033797-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None',
    'strict-transport-security': 'max-age=31536000; includeSubDomains; preload',
    'x-content-type-options': 'nosniff',
    'x-ratelimit-limit-requests': '10000',
    'x-ratelimit-limit-tokens': '200000',
    'x-ratelimit-remaining-requests': '9999',
    'x-ratelimit-remaining-tokens': '163460',
    'x-ratelimit-reset-requests': '8.64s',
    'x-ratelimit-reset-tokens': '10.962s',
    'x-request-id': 'req_1350ca15ff92d05955cd79b201aae3b5'
  },
  request_id: 'req_1350ca15ff92d05955cd79b201aae3b5',
  error: {
    message: "This model's maximum context length is 16385 tokens. However, your messages resulted in 30501 tokens. Please reduce the length of the messages.",
    type: 'invalid_request_error',
    param: 'messages',
    code: 'context_length_exceeded'
  },
  code: 'context_length_exceeded',
  param: 'messages',
  type: 'invalid_request_error'
}
5:57:13 AM [error] POST /api/files 500 in 4029ms :: {"error":"Upload failed","detail":"400 This model's maximum context length is...
[Auth] Deserializing user: 150
[Auth] Deserializing user: 150
[Tasks] ====== Starting task fetch =====