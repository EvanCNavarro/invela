# Handling Large PDF Files for OpenAI Document Classification

This document outlines best practices and recommended adjustments to effectively manage large PDF file uploads, ensuring the OpenAI GPT classification functionality operates reliably within API token limits.

## Current Issue

Uploading and processing large PDF files currently leads to exceeding OpenAI's API token limits, causing failures during document classification.

---

## Recommended Solutions

### 1. Chunking of Text

Implement logic to extract and send only portions of large documents to OpenAI. For example:
- Extract only the first 1-3 pages of the PDF (often sufficient for document classification).
- Target a maximum of approximately **4000-8000 characters (~1000-2000 tokens)** per API request.

### Implementation Example:
```javascript
// Recommended approach
const MAX_TEXT_CHARS = 8000; // adjust based on token limits
const extractedText = extractTextFromFirstPages(pdf, 3); // use PDF parsing lib

const prompt = `
You are an expert compliance analyst. Classify the following document snippet into exactly one of:
- SOC 2 Audit Report
- ISO 27001 Certification
- Penetration Test Report
- Business Continuity Plan
- Other Documents

Text:
${extractedText}

Return only the exact document type.`;
```

## Recommended Strategies:

### 1. **Chunking of Text**
- Extract content from the first 1-3 pages (most critical metadata often appears here).
- Or extract a representative text portion (first 8000 characters).

### 2. **Semantic Pre-filtering (Optional)**
- Use text embeddings to preprocess and determine relevant sections prior to classification.
- Reduces irrelevant content being processed, thus minimizing token usage.

### 2. **Error Handling & API Token Management**
- Implement error handling specifically for token limit errors:
  - If API call fails with token errors, automatically retry with fewer characters.
- Log these errors clearly for future debugging.

Example retry logic pseudocode:

```javascript
async function classifyDocumentWithRetry(text) {
  let currentLength = MAX_TEXT_CHARS;
  while(currentAttempt <= maxAttempts) {
    try {
      const result = await classifyWithOpenAI(text.slice(0, currentChars));
      return result;
    } catch (error) {
      if (isTokenLimitError(error)) {
        reduceTextSize(); // reduce extractedText size
      } else {
        handleOtherErrors();
      }
  }
}
```

### 3. **Fallback & Manual Intervention**
- For cases where the classification isn't clear, default classification to `Other Documents`.
- Provide the user an option for manual classification if automation results seem uncertain.

Example fallback logic:
```javascript
if (!classificationResult || confidenceScoreLow(classification)) {
  classificationResult = "Other Documents";
  // Notify users for manual confirmation
}
```

### 4. **Optimized Document Extraction Tools**
- Recommended libraries for PDF text extraction:
  - [`pdf-lib`](https://github.com/Hopding/pdf-lib)
  - [`pdf-parse`](https://www.npmjs.com/package/pdf-parse)
  - [`pdf.js`](https://mozilla.github.io/pdf.js/)

## Final Database Structure Example

After classification, store document type:

```json
{
  "name": "DataTechCompany_SOC2_Report_2025.pdf",
  "path": "uploads/1710723412-abc-DataTechCompany_SOC2_Report_2025.pdf",
  "type": "application/pdf",
  "size": 6291456,
  "user_id": "user_123",
  "company_id": "company_456",
  "status": "uploaded",
  "document_type": "SOC 2 Audit Report", // <-- classified result
  "created_at": "2025-03-17T00:00:00Z",
  "updated_at": "2025-03-17T00:00:00Z",
  "version": "1.0",
  "download_count": 0
}
```

## Final Workflow Recommendation:

| Step | Action                                    | Description |
|------|-------------------------------------------|-------------|
| 1    | File upload & validation                  | No change   |
| 2    | Server-side storage                       | No change   |
| 2B   | Extract limited content from PDF          | New step âœ… |
| 3    | Send text snippet to OpenAI for analysis  | New step for classification |
| 4    | Store classification result               | New DB field (`document_type`) |
| 5    | Respond to client                         | UI updates based on classification |

---

This implementation should reliably handle large documents and ensure smooth integration with OpenAI classification.